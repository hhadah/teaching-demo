---
title: "Linear Regression"
author: "Hussain Hadah"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  xaringan::moon_reader:
    css: ["default", "assets/sydney-fonts.css", "assets/sydney.css"]
    self_contained: false # if true, fonts will be stored locally
    seal: true # show a title slide with YAML information
    includes:
      in_header: "assets/mathjax-equation-numbers.html"
    nature:
      beforeInit: ["assets/remark-zoom.js", "https://platform.twitter.com/widgets.js"]
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: '16:9' # alternatives '16:9' or '4:3' or others e.g. 13:9
      navigation:
        scroll: false # disable slide transitions by scrolling
---
name: toc
layout: true
<div style="position: absolute;left:20px;bottom:5px;color:black;font-size: 12px;">`r rmarkdown::metadata$author` (UH) | `r rmarkdown::metadata$subtitle` | `r format(Sys.time(), '%d %B %Y')`</div>

<!--- `r rmarkdown::metadata$subtitle` | `r format(Sys.time(), '%d %B %Y')`-->

---

```{r, load_refs, echo=FALSE, cache=FALSE, message=FALSE}
library(RefManageR)
BibOptions(check.entries = FALSE, 
           bib.style = "authoryear", 
           cite.style = 'authoryear', 
           style = "markdown",
           hyperlink = FALSE, 
           dashed = FALSE)
myBib <- ReadBib("assets/example.bib", check = FALSE)
top_icon = function(x) {
  icons::icon_style(
    icons::fontawesome(x),
    position = "fixed", top = 10, right = 10
  )
}
```

```{r setup, include=FALSE}
xaringanExtra::use_scribble() ## Draw on slides. Requires dev version of xaringanExtra.

options(htmltools.dir.version = FALSE)
library(knitr)
opts_chunk$set(
  fig.align="center",  
  fig.height=4, fig.width=6,
  out.width="748px", out.length="520.75px",
  dpi=300, #fig.path='Figs/',
  cache=F#, echo=F, warning=F, message=F
  )
```

```{r data, include=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, hrbrthemes, sysfonts, 
               showtext,  gghighlight)

load(file.path("/Users/hhadah/Documents/GiT/teaching-demo/linear-regression","parenthood.Rdata"))

parenthood <- parenthood %>%
  rename(grumpiness = dan.grump,
         hours_slept = dan.sleep,
         dogs = baby.sleep
  )


font_add_google("Fira Sans", "firasans")
font_add_google("Fira Code", "firasans")

showtext_auto()
options(modelsummary_format_numeric_latex = "mathmode")
showtext_opts(dpi = 300)

theme_customs <- function() {
  theme_minimal(base_family = "IBM Plex Sans Condensed") +
    theme(panel.grid.minor = element_blank(),
          plot.background = element_rect(fill = "white", color = NA),
          plot.title = element_text(face = "bold", size = rel(2)),
          axis.title = element_text(face = "bold"),
          strip.text = element_text(face = "bold"),
          strip.background = element_rect(fill = "grey80", color = NA),
          legend.title = element_text(face = "bold", size = rel(1)),
          axis.text.y  = element_text(size = 18),
          axis.text.x  = element_text(size = 18),
          axis.title.x = element_text(size = 20),
          axis.title.y = element_text(size = 20),
          panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank(),
          axis.line = element_line(colour = "black"),
          legend.text = element_text(size = rel(1)))
}
```

```{css, echo=F}
    /* Table width = 100% max-width */

    .remark-slide table{
        width: 100%;
    }

    /* Change the background color to white for shaded rows (even rows) */

    .remark-slide thead, .remark-slide tr:nth-child(2n) {
        background-color: white;
    }
    .remark-slide thead, .remark-slide tr:nth-child(n) {
        background-color: white;
    }

    .cell_data--negative {
        content: "-"; /* Add a negative sign before the number */
        margin-right: 2px; /* Add some space between the sign and the number */
        text-decoration: none; /* Remove the underline */
    }
```

## Table of contents

1. [Prologue](#prologue)
2. [Linear Regression](#linear-regression)
4. [Deriving the Regression Equation](#deriving-the-regression-equation)
5. [Ordinary Least Squares](#ols-regression)
5. [Running a Linear Regression in R](#ols-in-r)

---
name: prologue
class: segue-red

# Prologue

---

## What We Will Learn

.blockquote[
### `r icons::fontawesome("location-arrow")` Aim

#### 1. Introduce Linear Regression 

#### 2. Understand the Intuition of Linear Regression 

#### 3. Deriving the Regression Equation

#### 4. Running a Linear Regression in R
]

???
After today's lecture, you will have what a linear regression model is, to derive a regression equation, how to run a linear regression in R, and how to interpret the results.

---
name: linear-regression
class: segue-red

# Linear Regression

???
Let's start!

---
## What is a linear regression model?

```{r regression0, fig.cap="Scatterplot showing grumpiness as a function of hours slept.", echo=FALSE, warning=FALSE}

parenthood |> 
  ggplot(aes(x = hours_slept, y = grumpiness)) +
  geom_point() +
  theme_customs() +
  labs(x = "My sleep (hours)",
       y = "My grumpiness (0-100)")
```
???
- I belive the best way to understand what a regression is by presenting a scatterplot from a data of sleep. Let's say that the x axis is the hours of sleep I get on a specific day, and the y axis is my grumpiness on that day.

- So each dot is a data point for a specific day.

- So we can investigate at each specific day how much grumpiness I had based on the hours of sleep I got.

- For example....

- So by looking at the data, we can see that there is a relationship between the hours of sleep and my grumpiness

---
count: false
## What is a linear regression model?

```{r regression2, fig.cap="Scatterplot showing grumpiness as a function of hours slept.", echo=FALSE, warning=FALSE, fig.height=3}

parenthood |> 
  ggplot(aes(x = hours_slept, y = grumpiness)) +
  geom_point() +
  theme_customs() +
  theme(axis.title.y = element_text(size = 15)) +
  labs(x = "My sleep (hours)",
       y = "My grumpiness (0-100)")
```

- We can predict my grumpiness based on the data points

---
count: false

## What is a linear regression model?

```{r regression3, fig.cap="Scatterplot showing grumpiness as a function of hours slept.", echo=FALSE, warning=FALSE, fig.height=3}

parenthood |> 
  ggplot(aes(x = hours_slept, y = grumpiness)) +
  geom_point() +
  geom_vline(xintercept = 7, color = "red", linetype = "dashed") +
  gghighlight(hours_slept < 7.1 & hours_slept >  6.9) + 
  theme_customs() +
  theme(axis.title.y = element_text(size = 15)) +
  labs(x = "My sleep (hours)",
       y = "My grumpiness (0-100)")
```

- We can predict my grumpiness based on the data points
- How grumpy could I be if I had 7 hours of sleep?

???
We can also predict my grumpiness.

Let's say that I am going to have 7 hours of sleep. How grumpy could I be?

---
count: false

## What is a linear regression model?

```{r regression3a, fig.cap="Scatterplot showing grumpiness as a function of hours slept.", echo=FALSE, warning=FALSE, fig.height=3}
parenthood |> 
  ggplot(aes(x = hours_slept, y = grumpiness)) +
  geom_point() +
  geom_vline(xintercept = 10, color = "red", linetype = "dashed") +
  geom_vline(xintercept = 12, color = "blue", linetype = "dashed") +
  theme_customs() +
  theme(axis.title.y = element_text(size = 15)) +
  labs(x = "My sleep (hours)",
       y = "My grumpiness (0-100)")+
  scale_y_continuous(limits = c(10, 120))
```

- You could also predict out of sample values

???
You could also predict out of sample values.

Tell me how grumpy I could be if I had 10 hours of sleep?

What about 12?

---
count: false

## What is a linear regression model?

```{r regression3b, fig.cap="Scatterplot showing grumpiness as a function of hours slept.", echo=FALSE, warning=FALSE, fig.height=3}
parenthood |> 
  ggplot(aes(x = hours_slept, y = grumpiness)) +
  geom_point() +
  geom_vline(xintercept = 4, color = "red", linetype = "dashed") +
  theme_customs() +
  theme(axis.title.y = element_text(size = 15)) +
  labs(x = "My sleep (hours)",
       y = "My grumpiness (0-100)")+
  scale_y_continuous(limits = c(20, 120))
```

- You could also predict out of sample values

???

What about 4?

---
## Predict my grumpiness given any hours of sleep

```{r regression4, fig.cap="Scatterplot showing grumpiness as a function of hours slept.", echo=FALSE, warning=FALSE}

parenthood |> 
  ggplot(aes(x = hours_slept, y = grumpiness)) +
  geom_point() +
  theme_customs() +
  labs(x = "My sleep (hours)",
       y = "My grumpiness (0-100)")
```

???
So, we can use the data to predict and make explinations about the relationship between the hours of sleep and my grumpiness.

When we predicted my out of sample grumpiness, we drew a line that was the best fit for the data.
---
## Regression: “Best Fitting” Line Through Cloud of Points

```{r regression5, fig.cap="Scatterplot showing grumpiness as a function of hours slept.", echo=FALSE, warning=FALSE, results='hide', message = FALSE}

parenthood |> 
  ggplot(aes(x = hours_slept, y = grumpiness)) +
  geom_point() +
  suppressMessages(geom_smooth(method = "lm", se = FALSE)) +
  theme_customs() +
  labs(x = "My sleep (hours)",
       y = "My grumpiness (0-100)")
```
???
And this line is called the regression line.
---
## Regression: “Best Fitting” Line Through Cloud of Points

```{r regression6, fig.cap="Two regression lines.", echo=FALSE, warning=FALSE, results='hide', message = FALSE}

library(gridExtra)
plot1 <- parenthood %>%
  ggplot(aes(x = hours_slept, y = grumpiness)) +
  geom_point() +
  suppressMessages(geom_smooth(method = "lm", se = FALSE)) +
  theme_customs() +
  theme(axis.title.x = element_text(size = 12)) + # Adjust size of x axis title
  theme(axis.title.y = element_text(size = 12)) + # Adjust size of y axis title
  labs(x = "My sleep (hours)",
       y = "My grumpiness (0-100)")

plot2 <- parenthood %>%
  ggplot(aes(x = hours_slept, y = grumpiness)) +
  geom_point() +
  geom_abline(slope = -0.5, intercept = 67) +
  theme_customs() +
  theme(axis.title.x = element_text(size = 12)) + # Adjust size of x axis title
  theme(axis.title.y = element_text(size = 12)) + # Adjust size of y axis title
  labs(x = "My sleep (hours)",
       y = "My grumpiness (0-100)")

grid.arrange(plot1, plot2, ncol = 2)
```

???
A regression line is the line that is best fitting line through the cloud of data points

To understand why it's the best fitting line, let look at this graph

Tell me which line is the best fitting line? Why? Which one makes the best predictions?

It's the one on the left because it minimizes the distance between the predicted data (the line) and the actual data (the points).

---

## Essential parts of regression

.pull-left[
.content-box-purple.large[**Y**]

.content-box-yellow[Outcome variable]

.content-box-yellow[Response variable]

.content-box-yellow[Dependent variable]

.content-box-purple[Thing you want to explain or predict]
]

???
Now to some technical terms and definitions

In a regression there are two type of variables

The first type is the outcome variable, also called response, dependent, or explained variable.

This variable is the thing you want to explain or predict.

--

.pull-right[
.content-box-purple.large[**X**]

.content-box-yellow[Explanatory variable]

.content-box-yellow[Predictor variable]

.content-box-yellow[Independent variable]

.content-box-purple[Thing you use to explain or predict **Y**]
]

???
The second type of variable is the explanatory variable, also called predictor, independent, or explanatory variable.

This variable is the thing you use to explain or predict the outcome variable.


So in my example, the outcome variable is my grumpiness and the explanatory variable is my hours of sleep.
---
## Identify variables

.pull-left[
.Large[.content-box-purple[
A study examines the effect of smoking on lung cancer
]]

.Large[.content-box-purple[
Researchers predict genocides by looking at negative media coverage, revolutions in neighboring countries, and economic growth
]]
]

.pull-right[
.Large[.content-box-purple[
You want to see if taking more AP classes in high school improves college grades
]]

.Large[.content-box-purple[
Netflix uses your past viewing history, the day of the week, and the time of the day to guess which show you want to watch next
]]
]

???
Let's identify the outcome and explanatory variables in some examples

What is the outcome variable and what are the explanatory variables in each example?

In the first example, the outcome variable is lung cancer and the explanatory variable is smoking.

In the second example, the outcome variable is genocides and the explanatory variables are negative media coverage, revolutions in neighboring countries, and economic growth.

In the third example, the outcome variable is college grades and the explanatory variable is AP classes.

In the fourth example, the outcome variable is the next show you want to watch and the explanatory variables are your past viewing history, the day of the week, and the time of the day.

---

# Two purposes of regression

.pull-left[
.content-box-purple[Prediction]

.content-box-yellow[Forecast the future]

.content-box-yellow[Focus is on **Y**]

.Large[.content-box-green[
Netflix trying to guess your next show
]]

.Large[.content-box-green[
Predicting who will enroll in SNAP
]]
]

???
There are two purposes of regression

The first being prediction

In this case, you are trying to forecast the future

You would focus on the outcome variable Y 

So in our examples, netflix will try to predict which show you want to watch next and the researchers will try to predict who will enroll in SNAP

--

.pull-right[
.content-box-purple[Explanation]

.content-box-yellow[Explain effect of **X** on **Y**]

.content-box-yellow[Focus is on **X**]

.Large[.content-box-green[
Netflix looking at the effect of the time of day on show selection
]]

.Large[.content-box-green[
Measuring the effect of SNAP on poverty reduction
]]
]

???
The second purpose of regression is explanation

You would want to explain the effect of X on Y

You would focus on the explanatory variable X

So in our examples, netflix will look at the effect of the time of day on show selection and the researchers will measure the effect of SNAP on poverty reduction


---
## How Can we do this?

.Large[.content-box-green[
Plot **X** and **Y**
]]

--

.large[.content-box-red[
Draw a line that approximates the relationship
]]

.small[.content-box-red[
and that would plausibly work for data not in the sample!
]]

--

.large[.content-box-red[
Find mathy parts of the line
]]

--

.large[.content-box-red[
Interpret the math
]]

---
## What is a Linear Regression?

.Large[.content-box-purple[
A linear regression is a tool used by economists to analyze relationships between interval scale predictors and interval scale outcomes
]]

--
- What does this remind you of?

--
- Hint: ________ is not causation

--
  - .brand-red[Correlations]

???
This is a definition of a linear regression

A linear regression is a tool used by economists to analyze relationships between interval scale predictors and interval scale outcomes


---
name: deriving-the-regression-equation
class: segue-red

# Deriving the Regression Equation

---
## The Regression Equation

#### To derive the regression, let remember some high school math

The formula of a straight line is given by:
$$
y = mx + c
$$
--

- There are two variables, $x$ and $y$

- There are two coefficients, $m$ and $c$

--
- $\pmb{m}$: is the slope of a line and is $y$ divided by the change in $x$

- $\pmb{c}$: is the y-intercept 

--

#### We use the same exact formula to describe a linear regression line:

$$
\hat{Y_i} = \beta_0 + \beta_1 X_i
$$

---
## The Regression Equation (cont.)

$$
\hat{Y_i} = \beta_0 + \beta_1 X_i
$$

- $X_i$: is the value of predictor variable for the _i_ th observation
  - numbers of hours of sleep I got on day _i_
- $Y_i$: is the corresponding value of the outcome variable (i.e., my grumpiness on that day)
- $\hat{Y_i}$: is the predicted value of $Y_i$ for a given value of $X_i$
  - $Y_i$ is actual data
  - $\hat{Y_i}$ is the estimate
- $\beta_0$: is the y-intercept
- $\beta_1$: is the slope of the line

---
## The Regression Equation (cont.)

- Not all the data points will fall on the regression line
- In other words, $Y_i$ are not identical to the predicted values from the model $\hat{Y_i}$

--
- The difference between the actual and predicted values is called the **residuals**, $\epsilon_i$:
$$
\epsilon_i = Y_i - \hat{Y_i}
$$

--
- Now we know everything we need to know to write down a linear regression model as:
$$
\hat{Y_i} = \beta_0 + \beta_1 X_i + \epsilon_i
$$

---
name: ols-regression
class: segue-red

# Ordinary Least Squares 

---
## Estimating a Linear Regression Model

- How to we chose the values of $\beta_0$ and $\beta_1$?


```{r regression7, echo=FALSE}
regressionImg <- list()
emphCol <- rgb(0,0,1)
emphColLight <- rgb(.5,.5,1)
emphGrey <- grey(.5)
eps <- TRUE
colour <- TRUE
width <- 6
height <- 6

drawBasicScatterplot <- function(dotcol,title) {
  
    plot( parenthood$hours_slept,
          parenthood$grumpiness,
          xlab = "My sleep (hours)",
          ylab = "My grumpiness (0-100)",
          col= dotcol,
          main = title,
          font.main=1,
          pch=19)
  
  }
good.coef <- lm( grumpiness ~ hours_slept, parenthood)$coef
bad.coef <- c(80,-3)
par(mfrow=c(1,2))
drawBasicScatterplot( emphGrey, " " )
	abline( good.coef, col=ifelse(colour,emphCol,"black"), lwd=3 )
	for(i in seq_along(parenthood$hours_slept)) {
	  xval <- parenthood$hours_slept[i]*c(1,1)
	  yval <- c(parenthood$grumpiness[i],good.coef[1]+good.coef[2]*parenthood$hours_slept[i])
	  lines(xval,yval,type='l', col = emphGrey)
	}
drawBasicScatterplot(emphGrey, " " )
	abline( bad.coef, col=ifelse(colour,emphCol,"black"), lwd=3 )
	for(i in seq_along(parenthood$hours_slept)) {
	  xval <- parenthood$hours_slept[i]*c(1,1)
	  yval <- c(parenthood$grumpiness[i],bad.coef[1]+bad.coef[2]*parenthood$hours_slept[i])
	  lines(xval,yval,type='l', col = emphGrey)
	}

```

---
## Least Squares Regression Predict Using a Line

### The Prediction
Predict my grumpiness $\hat{Y_i} = \beta_0 + \beta_1 X_i$ if I slept $x$ hours

- How to we chose the values of $\beta_0$ and $\beta_1$?

- The lines regression choose the values of $\beta_0$ and $\beta_1$ that minimize the sum of the squared residuals $\sum_{i=1}^n \epsilon_i^2$

#### The sum of the squared residuals is given by:

$$
\sum_{i=1}^n (Y_i - \hat{Y_i})^2
$$

- When minimized, we will get the optimal estiamted $\hat{\beta_0}$ and $\hat{\beta_1}$?

- The more technical name for this estimation process is _.brand-blue[ordinary least squares (OLS) regression]_

---
name: ols-in-r
class: segue-red

# Regression in R

---
## Using the `lm()` function

- The `lm()` function is used to fit linear models in R
- It's a complicated function, type `?lm` to see the documentation
- For this class, we will only use the basic syntax that we've seen before

--
- A `formula`
- A `data` frame

```{r, eval = FALSE}
lm(formula = Y ~ X, data = data.frame)
```
---
## Using the Sleep Data


- First we load the data

```{r, eval = FALSE}
read.csv("/PATH/teaching-demo/parenthood.csv")
```

- Then we run the regression
- `hours_slept` is the predictor variable or dependent variable
- `grumpiness` is the outcome variable or independent variable

```{r, eval = FALSE}
regression <- lm(formula = grumpiness ~ hours_slept, data = parenthood)
```

- You can print the results using the following options

```{r, eval = FALSE}
print(regression)
summary(regression)
tidy(regression) # broom package
modelsummary(regression) # modelsummary package

```
---
## Using the Sleep Data (cont.)

```{r, eval = TRUE, include = FALSE}
regression <- lm(formula = grumpiness ~ hours_slept, data = parenthood)
```

- The `print()` function gives us the regression equation and the coefficients

```{r, eval = TRUE}
print(regression)
```
---
## Using the Sleep Data (cont.)

- The `summary()` function gives us a lot of information about the regression
```{r, eval = TRUE}
summary(regression)
```

---
## Using the Sleep Data (cont.)

- The `modelsummary()` produces a nice table of the regression results that is easy to read and customize

```{r, eval = TRUE, include = FALSE}
options("modelsummary_format_numeric_html" = "plain")
```

.scroll-output[
```{r, eval = TRUE}
library(modelsummary)
modelsummary(regression, gof.omit = c("nobs", "r.squared"))
```
]

---
## Using the Sleep Data (cont.)

- The `tidy()` function produces a nice table output of the results

```{r, eval = TRUE}
library(broom)
tidy(regression)
```

---
# Translating Results to Math

$$
\widehat{\text{Grumpiness}} = 125.9563 + (-8.9368) \times \text{Sleep} 
$$

--

- In other words, the estimates that would draw the best fitting line are:

  - $\hat{\beta_0} = 125.9563$, intercept
  - $\hat{\beta_1} = -8.9368$


---
# Interpreting the Regression Results

$$
\widehat{\text{Grumpiness}} = 125.9563 + (-8.9368) \times \text{Sleep} 
$$

--
.font80[.content-box-purple[
On average, a one hour increase in sleep is associated with 8.9368 lower Grumpiness, holding everything else constant
]]

--
.font80[.content-box-purple[
The intercept is the expected grumpinness of 125.9563 when sleep is 0 hours `r emo::ji("rage")`
]]

---
# Predicting Grumpiness Given a 5 Hour Sleep

$$
\widehat{\text{Grumpiness}} = 125.9563 + (-8.9368) \times \text{Sleep} 
$$

- By hand:

```{r, eval = TRUE}
125.9563 + (-8.9368 * 5)
```

--
- Using `predict()` function

```{r, eval = TRUE}
grumpiness <- data.frame(hours_slept = 5)
predict(regression, newdata = grumpiness)
```

---
## Multiple Linear Regression

- The example we just did was a simple linear regression with a single variable

- Most research projects have multiple predictors

- Out example predicted the effect of sleep on grumpiness

- We could add another predictor, like the number of hours my dogs sleep

### In R

```{r, eval = TRUE}
regression2 <- lm(formula = grumpiness ~ hours_slept + dogs, data = parenthood)
print(regression2)
```
---
## Formula for the General caused

\begin{align*}
Y_i &= \beta_0 + (\sum_{k = 1}^K \beta_k X_{ik}) + \epsilon_i \\
&= \beta_0 + \beta_1 X_{i1} + \beta_2 X_{i2} + \dots + \beta_K X_{iK} + \epsilon_i
\end{align*}

---
## How do we Know if a Model is Good?

### The $R^2$

- The $R^2$ is a measure of how well the model fits the data
- It is the proportion of the variance in the outcome variable that is explained by the model

$$
R^2 = \frac{\text{Explained Variation}}{\text{Total Variation}}
$$

--
### We can calculate it using we need to do the following

1. Sum of the squared residuals:
$$
SS_{res} = \sum_i (\epsilon_i)^2 =\sum_i (Y_i - \hat{Y_i})^2
$$

2. Total Sum of Squares:
$$
SS_{tot} = \sum_i (Y_i - \bar{Y_i})^2
$$

---
## In R

```{r, eval = TRUE}
X <- parenthood$hours_slept # predictor
Y <- parenthood$grumpiness # outcome
```

- To calculate $\hat{Y_i}$:

```{r, eval = TRUE}
Y.pred <- -8.94 * X + 125.97
```

--
- The sum squared residuals (SSR):

```{r, eval = TRUE}
SS.res <- sum((Y - Y.pred)^2)
```

--
- The total sum of squares (SST):

```{r, eval = TRUE}
SS.tot <- sum((Y - mean(Y))^2)
paste0("SSR: ", SS.res, " SST: ", SS.tot)
```

---
## In R (cont.)

### The $R^2$

\begin{align*}
R^2 = 1 - \frac{SS_{res}}{SS_{tot}}
\end{align*}

#### Which we can now calculate:


```{r, eval = TRUE}
R.squared <- 1 - (SS.res / SS.tot)
print( R.squared )
```

--

- The $R^2$ is the proportion of the variance in the outcome variable that is explained by the model
- It is sometimes called the .brand-red[coefficient of determination]
- The proportion of the variance in the outcome variable that can be accounted for by the predictor
- So an $R^2$ of 0.82 means that 82% of the variance in my grumpiness (Y) can be explained by my sleep (X)

---
## Relationship Between Regression and Correlations

- As I said at the beggining, regression is similiar to correlation from earlier in the semester

- $r$ is the correlation coefficient

- $R^2$ is identical to $r^2$

```{r, eval = TRUE}
r <- cor(X, Y)
print(r^2)
```

```{r, eval = TRUE} 
R.squared <- 1 - (SS.res / SS.tot)
print( R.squared )
```


```{r gen_pdf, include = FALSE, cache = FALSE, eval = FALSE}
# https://hhadah.github.io/MicroSlides/MyPresentations/intro/intro.html

infile = list.files(path = "/Users/hhadah/Documents/GiT/teaching-demo/index.html", pattern = 'index.html')
pagedown::chrome_print(input = infile, timeout = 100)
xaringan::inf_mr() 
```

